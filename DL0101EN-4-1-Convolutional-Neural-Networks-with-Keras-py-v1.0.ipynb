{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://cognitiveclass.ai/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0101ENSkillsNetwork945-2022-01-01\"><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0101EN-SkillsNetwork/images/IDSN-logo.png\" width=\"400\"> </a>\n",
    "\n",
    "<h1 align=center><font size = 5>Convolutional Neural Networks with Keras</font></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will learn how to use the Keras library to build convolutional neural networks. We will also use the popular MNIST dataset and we will compare our results to using a conventional neural network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Convolutional Neural Networks with Keras</h2>\n",
    "\n",
    "<h3>Objective for this Notebook<h3>    \n",
    "<h5> 1. How to use the Keras library to build convolutional neural networks.</h5>\n",
    "<h5> 2. Convolutional Neural Network with One Convolutional and Pooling Layers.</h5>\n",
    "<h5> 3. Convolutional Neural Network with Two Convolutional and Pooling Layers.</h5>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "<font size = 3>\n",
    "      \n",
    "1. <a href=\"#item41\">Import Keras and Packages</a>   \n",
    "2. <a href=\"#item42\">Convolutional Neural Network with One Convolutional and Pooling Layers</a>  \n",
    "3. <a href=\"#item43\">Convolutional Neural Network with Two Convolutional and Pooling Layers</a>  \n",
    "\n",
    "</font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item41'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Keras and Packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing the keras libraries and the packages that we would need to build a neural network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented. \n",
    "# If you run this notebook on a different environment, e.g. your desktop, you may need to uncomment and install certain libraries.\n",
    "\n",
    "#!pip install numpy==1.21.4\n",
    "#!pip install pandas==1.3.4\n",
    "#!pip install keras==2.1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with convolutional neural networks in particular, we will need additional packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv2D # to add convolutional layers\n",
    "from keras.layers.convolutional import MaxPooling2D # to add pooling layers\n",
    "from keras.layers import Flatten # to flatten data for fully connected layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item42'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Layer with One set of convolutional and pooling layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import data\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's normalize the pixel values to be between 0 and 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = X_train / 255 # normalize training data\n",
    "X_test = X_test / 255 # normalize test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's convert the target variable into binary categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "num_classes = y_test.shape[1] # number of categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's define a function that creates our model. Let's start with one set of convolutional and pooling layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convolutional_model():\n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (5, 5), strides=(1, 1), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's call the function to create the model, and then let's train it and evaluate it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 35s 576us/step - loss: 0.2753 - acc: 0.9243 - val_loss: 0.1023 - val_acc: 0.9690\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 35s 577us/step - loss: 0.0789 - acc: 0.9776 - val_loss: 0.0619 - val_acc: 0.9792\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 34s 573us/step - loss: 0.0547 - acc: 0.9841 - val_loss: 0.0463 - val_acc: 0.9841\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 34s 571us/step - loss: 0.0431 - acc: 0.9871 - val_loss: 0.0421 - val_acc: 0.9862\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 36s 592us/step - loss: 0.0356 - acc: 0.9890 - val_loss: 0.0448 - val_acc: 0.9841\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 34s 573us/step - loss: 0.0296 - acc: 0.9906 - val_loss: 0.0355 - val_acc: 0.9889\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 34s 569us/step - loss: 0.0238 - acc: 0.9925 - val_loss: 0.0368 - val_acc: 0.9873\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 34s 572us/step - loss: 0.0214 - acc: 0.9932 - val_loss: 0.0344 - val_acc: 0.9887\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 35s 585us/step - loss: 0.0174 - acc: 0.9944 - val_loss: 0.0374 - val_acc: 0.9886\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 37s 611us/step - loss: 0.0145 - acc: 0.9956 - val_loss: 0.0421 - val_acc: 0.9865\n",
      "Accuracy: 0.9865 \n",
      " Error: 1.3499999999999943\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = convolutional_model()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=1)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting visualkeras\n",
      "  Downloading visualkeras-0.0.2-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from visualkeras) (8.1.0)\n",
      "Requirement already satisfied: numpy>=1.18.1 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from visualkeras) (1.21.6)\n",
      "Collecting aggdraw>=1.3.11 (from visualkeras)\n",
      "  Downloading aggdraw-1.3.16-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (989 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m989.8/989.8 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: aggdraw, visualkeras\n",
      "Successfully installed aggdraw-1.3.16 visualkeras-0.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install visualkeras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import visualkeras\n",
    "visualkeras.layered_view(model, to_file='output.png').show() # write and show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=390x128 at 0x7F592472AC10>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualkeras.layered_view(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Layer with two sets of convolutional and pooling layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's redefine our convolutional model so that it has two convolutional and pooling layers instead of just one layer of each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convolutional_model():\n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(8, (2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's call the function to create our new convolutional neural network, and then let's train it and evaluate it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 39s 658us/step - loss: 0.4687 - acc: 0.8699 - val_loss: 0.1311 - val_acc: 0.9608\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 37s 621us/step - loss: 0.1158 - acc: 0.9653 - val_loss: 0.0823 - val_acc: 0.9747\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 39s 646us/step - loss: 0.0857 - acc: 0.9739 - val_loss: 0.0722 - val_acc: 0.9777\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 38s 634us/step - loss: 0.0698 - acc: 0.9787 - val_loss: 0.0610 - val_acc: 0.9805\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 37s 625us/step - loss: 0.0599 - acc: 0.9822 - val_loss: 0.0542 - val_acc: 0.9830\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 38s 641us/step - loss: 0.0517 - acc: 0.9840 - val_loss: 0.0497 - val_acc: 0.9838\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 37s 621us/step - loss: 0.0468 - acc: 0.9853 - val_loss: 0.0441 - val_acc: 0.9863\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 39s 648us/step - loss: 0.0403 - acc: 0.9876 - val_loss: 0.0454 - val_acc: 0.9851\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 38s 625us/step - loss: 0.0367 - acc: 0.9892 - val_loss: 0.0441 - val_acc: 0.9869\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 39s 647us/step - loss: 0.0343 - acc: 0.9891 - val_loss: 0.0412 - val_acc: 0.9872\n",
      "Accuracy: 0.9872 \n",
      " Error: 1.2800000000000011\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = convolutional_model()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=1)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=240x128 at 0x7F59240D4850>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualkeras.layered_view(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thank you for completing this lab!\n",
    "\n",
    "This notebook was created by [Alex Aklson](https://www.linkedin.com/in/aklson/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0101ENSkillsNetwork945-2022-01-01). I hope you found this lab interesting and educational. Feel free to contact me if you have any questions!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Change Log\n",
    "\n",
    "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
    "|---|---|---|---|\n",
    "| 2020-09-21  | 2.0  | Srishti  |  Migrated Lab to Markdown and added to course repo in GitLab |\n",
    "\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "## <h3 align=\"center\"> © IBM Corporation 2020. All rights reserved. <h3/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is part of a course on **Coursera** called *Introduction to Deep Learning & Neural Networks with Keras*. If you accessed this notebook outside the course, you can take this course online by clicking [here](https://cocl.us/DL0101EN_Coursera_Week4_LAB1).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Copyright &copy; 2019 [IBM Developer Skills Network](https://cognitiveclass.ai/?utm_medium=dswb&utm_source=bducopyrightlink&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0101ENSkillsNetwork945-2022-01-01&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0101ENSkillsNetwork945-2022-01-01).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
